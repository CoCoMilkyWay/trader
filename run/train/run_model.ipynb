{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 14:22:53.549 | WARNING  | qlib.tests.data:qlib_data:195 - Data already exists: ./.qlib/qlib_data/cn_data, the data download will be skipped\n",
      "\tIf downloading is required: `exists_skip=False` or `change target_dir`\n",
      "[30348:MainThread](2024-08-18 14:22:53,551) INFO - qlib.Initialization - [config.py:416] - default_conf: client.\n",
      "[30348:MainThread](2024-08-18 14:22:53,553) WARNING - qlib.Initialization - [__init__.py:64] - auto_path is False, please make sure None is mounted\n",
      "[30348:MainThread](2024-08-18 14:22:53,556) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[30348:MainThread](2024-08-18 14:22:53,558) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': WindowsPath('C:/Users/chuyin.wang/.qlib/qlib_data/cn_data')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost {'XGBoost': 'C:\\\\Users\\\\chuyin.wang\\\\Desktop\\\\share\\\\fin\\\\trader\\\\run\\\\train\\\\benchmarks\\\\XGBoost'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving files...\n",
      "\n",
      "[30348:MainThread](2024-08-18 14:22:53,630) INFO - qlib.qrun - [cli.py:78] - Render the template with the context: {}\n",
      "[30348:MainThread](2024-08-18 14:22:53,663) WARNING - qlib.workflow - [expm.py:230] - No valid experiment found. Create a new experiment with name XGBoost.\n",
      "[30348:MainThread](2024-08-18 14:22:53,674) INFO - qlib.workflow - [exp.py:258] - Experiment 1 starts running ...\n",
      "[30348:MainThread](2024-08-18 14:22:53,963) INFO - qlib.workflow - [recorder.py:341] - Recorder 7923125c92234017a81d831c321f4f59 starts running under Experiment 1 ...\n"
     ]
    }
   ],
   "source": [
    "#  Copyright (c) Microsoft Corporation.\n",
    "#  Licensed under the MIT License.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import fire\n",
    "import time\n",
    "import glob\n",
    "import yaml\n",
    "import shutil\n",
    "import signal\n",
    "import logging\n",
    "import inspect\n",
    "import tempfile\n",
    "import functools\n",
    "import statistics\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from operator import xor\n",
    "from pprint import pprint\n",
    "\n",
    "import qlib\n",
    "from qlib.workflow import R\n",
    "from qlib.tests.data import GetData\n",
    "import qlib\n",
    "from qlib.config import C\n",
    "from qlib.log import get_module_logger\n",
    "from qlib.model.trainer import task_train\n",
    "from qlib.utils import set_log_with_config\n",
    "from qlib.utils.data import update_config\n",
    "\n",
    "set_log_with_config(C.logging_config)\n",
    "logger = get_module_logger(\"qrun\", logging.INFO)\n",
    "\n",
    "# decorator to check the arguments\n",
    "def only_allow_defined_args(function_to_decorate):\n",
    "    @functools.wraps(function_to_decorate)\n",
    "    def _return_wrapped(*args, **kwargs):\n",
    "        \"\"\"Internal wrapper function.\"\"\"\n",
    "        argspec = inspect.getfullargspec(function_to_decorate)\n",
    "        valid_names = set(argspec.args + argspec.kwonlyargs)\n",
    "        if \"self\" in valid_names:\n",
    "            valid_names.remove(\"self\")\n",
    "        for arg_name in kwargs:\n",
    "            if arg_name not in valid_names:\n",
    "                raise ValueError(\"Unknown argument seen '%s', expected: [%s]\" % (arg_name, \", \".join(valid_names)))\n",
    "        return function_to_decorate(*args, **kwargs)\n",
    "\n",
    "    return _return_wrapped\n",
    "\n",
    "\n",
    "# function to handle ctrl z and ctrl c\n",
    "def handler(signum, frame):\n",
    "    os.system(\"kill -9 %d\" % os.getpid())\n",
    "\n",
    "signal.signal(signal.SIGINT, handler)\n",
    "\n",
    "# function to calculate the mean and std of a list in the results dictionary\n",
    "def cal_mean_std(results) -> dict:\n",
    "    mean_std = dict()\n",
    "    for fn in results:\n",
    "        mean_std[fn] = dict()\n",
    "        for metric in results[fn]:\n",
    "            mean = statistics.mean(results[fn][metric]) if len(results[fn][metric]) > 1 else results[fn][metric][0]\n",
    "            std = statistics.stdev(results[fn][metric]) if len(results[fn][metric]) > 1 else 0\n",
    "            mean_std[fn][metric] = [mean, std]\n",
    "    return mean_std\n",
    "\n",
    "# function to execute the cmd\n",
    "def execute(cmd, wait_when_err=False, raise_err=True):\n",
    "    print(\"Running CMD:\", cmd)\n",
    "    with subprocess.Popen(cmd, stdout=subprocess.PIPE, bufsize=1, universal_newlines=True, shell=True) as p:\n",
    "        for line in p.stdout: # type: ignore\n",
    "            sys.stdout.write(line.split(\"\\b\")[0])\n",
    "            if \"\\b\" in line:\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(0.1)\n",
    "                sys.stdout.write(\"\\b\" * 10 + \"\\b\".join(line.split(\"\\b\")[1:-1]))\n",
    "\n",
    "    if p.returncode != 0:\n",
    "        if wait_when_err:\n",
    "            input(\"Press Enter to Continue\")\n",
    "        if raise_err:\n",
    "            raise RuntimeError(f\"Error when executing command: {cmd}\")\n",
    "        return p.stderr\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# function to get all the folders benchmark folder\n",
    "def get_all_folders(models, exclude) -> dict:\n",
    "    folders = dict()\n",
    "    if isinstance(models, str):\n",
    "        model_list = models.split(\",\")\n",
    "        models = [m.lower().strip(\"[ ]\") for m in model_list]\n",
    "    elif isinstance(models, list):\n",
    "        models = [m.lower() for m in models]\n",
    "    elif models is None:\n",
    "        models = [f.name.lower() for f in os.scandir(\"benchmarks\")]\n",
    "    else:\n",
    "        raise ValueError(\"Input models type is not supported. Please provide str or list without space.\")\n",
    "    for f in os.scandir(\"benchmarks\"):\n",
    "        add = xor(bool(f.name.lower() in models), bool(exclude))\n",
    "        if add:\n",
    "            path = Path(\"benchmarks\") / f.name\n",
    "            folders[f.name] = str(path.resolve())\n",
    "    return folders\n",
    "\n",
    "\n",
    "# function to get all the files under the model folder\n",
    "def get_all_files(folder_path, dataset, universe=\"\") -> (str, str): # type: ignore\n",
    "    if universe != \"\":\n",
    "        universe = f\"_{universe}\"\n",
    "    yaml_path = str(Path(f\"{folder_path}\") / f\"*{dataset}{universe}.yaml\")\n",
    "    req_path = str(Path(f\"{folder_path}\") / f\"*.txt\")\n",
    "    yaml_file = glob.glob(yaml_path)\n",
    "    req_file = glob.glob(req_path)\n",
    "    if len(yaml_file) == 0:\n",
    "        return None, None\n",
    "    else:\n",
    "        return yaml_file[0], req_file[0]\n",
    "\n",
    "\n",
    "# function to retrieve all the results\n",
    "def get_all_results(folders) -> dict:\n",
    "    results = dict()\n",
    "    for fn in folders:\n",
    "        try:\n",
    "            exp = R.get_exp(experiment_name=fn, create=False)\n",
    "        except ValueError:\n",
    "            # No experiment results\n",
    "            continue\n",
    "        recorders = exp.list_recorders()\n",
    "        result = dict()\n",
    "        result[\"annualized_return_with_cost\"] = list()\n",
    "        result[\"information_ratio_with_cost\"] = list()\n",
    "        result[\"max_drawdown_with_cost\"] = list()\n",
    "        result[\"ic\"] = list()\n",
    "        result[\"icir\"] = list()\n",
    "        result[\"rank_ic\"] = list()\n",
    "        result[\"rank_icir\"] = list()\n",
    "        for recorder_id in recorders:\n",
    "            if recorders[recorder_id].status == \"FINISHED\": # type: ignore\n",
    "                recorder = R.get_recorder(recorder_id=recorder_id, experiment_name=fn)\n",
    "                metrics = recorder.list_metrics()\n",
    "                if \"1day.excess_return_with_cost.annualized_return\" not in metrics:\n",
    "                    print(f\"{recorder_id} is skipped due to incomplete result\")\n",
    "                    continue\n",
    "                result[\"annualized_return_with_cost\"].append(metrics[\"1day.excess_return_with_cost.annualized_return\"])\n",
    "                result[\"information_ratio_with_cost\"].append(metrics[\"1day.excess_return_with_cost.information_ratio\"])\n",
    "                result[\"max_drawdown_with_cost\"].append(metrics[\"1day.excess_return_with_cost.max_drawdown\"])\n",
    "                result[\"ic\"].append(metrics[\"IC\"])\n",
    "                result[\"icir\"].append(metrics[\"ICIR\"])\n",
    "                result[\"rank_ic\"].append(metrics[\"Rank IC\"])\n",
    "                result[\"rank_icir\"].append(metrics[\"Rank ICIR\"])\n",
    "        results[fn] = result\n",
    "    return results\n",
    "\n",
    "\n",
    "# function to generate and save markdown table\n",
    "def gen_and_save_md_table(metrics, dataset):\n",
    "    table = \"| Model Name | Dataset | IC | ICIR | Rank IC | Rank ICIR | Annualized Return | Information Ratio | Max Drawdown |\\n\"\n",
    "    table += \"|---|---|---|---|---|---|---|---|---|\\n\"\n",
    "    for fn in metrics:\n",
    "        ic = metrics[fn][\"ic\"]\n",
    "        icir = metrics[fn][\"icir\"]\n",
    "        ric = metrics[fn][\"rank_ic\"]\n",
    "        ricir = metrics[fn][\"rank_icir\"]\n",
    "        ar = metrics[fn][\"annualized_return_with_cost\"]\n",
    "        ir = metrics[fn][\"information_ratio_with_cost\"]\n",
    "        md = metrics[fn][\"max_drawdown_with_cost\"]\n",
    "        table += f\"| {fn} | {dataset} | {ic[0]:5.4f}±{ic[1]:2.2f} | {icir[0]:5.4f}±{icir[1]:2.2f}| {ric[0]:5.4f}±{ric[1]:2.2f} | {ricir[0]:5.4f}±{ricir[1]:2.2f} | {ar[0]:5.4f}±{ar[1]:2.2f} | {ir[0]:5.4f}±{ir[1]:2.2f}| {md[0]:5.4f}±{md[1]:2.2f} |\\n\"\n",
    "    pprint(table)\n",
    "    with open(\"table.md\", \"w\") as f:\n",
    "        f.write(table)\n",
    "    return table\n",
    "\n",
    "\n",
    "# read yaml, remove seed kwargs of model, and then save file in the temp_dir\n",
    "def gen_yaml_file_without_seed_kwargs(yaml_path, temp_dir):\n",
    "    with open(yaml_path, \"r\") as fp:\n",
    "        config = yaml.safe_load(fp)\n",
    "    try:\n",
    "        del config[\"task\"][\"model\"][\"kwargs\"][\"seed\"]\n",
    "    except KeyError:\n",
    "        # If the key does not exists, use original yaml\n",
    "        # NOTE: it is very important if the model most run in original path(when sys.rel_path is used)\n",
    "        return yaml_path\n",
    "    else:\n",
    "        # otherwise, generating a new yaml without random seed\n",
    "        file_name = yaml_path.split(\"/\")[-1]\n",
    "        temp_path = os.path.join(temp_dir, file_name)\n",
    "        with open(temp_path, \"w\") as fp:\n",
    "            yaml.dump(config, fp)\n",
    "        return temp_path\n",
    "\n",
    "\n",
    "class ModelRunner:\n",
    "    # def __init__(self):\n",
    "    #     self.run()\n",
    "        \n",
    "    def _init_qlib(self, exp_folder_name):\n",
    "        # init qlib\n",
    "        provider_uri = \"./.qlib/qlib_data/cn_data\"\n",
    "        GetData().qlib_data(target_dir=provider_uri, exists_skip=True)\n",
    "        qlib.init(\n",
    "            exp_manager={\n",
    "                \"class\": \"MLflowExpManager\",\n",
    "                \"module_path\": \"qlib.workflow.expm\",\n",
    "                \"kwargs\": {\n",
    "                    \"uri\": \"file:\" + str(Path(os.getcwd()).resolve() / exp_folder_name),\n",
    "                    \"default_exp_name\": \"Experiment\",\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # function to run the all the models\n",
    "    @only_allow_defined_args\n",
    "    def run(\n",
    "        self,\n",
    "        times=1,\n",
    "        models=['xgboost'], # None,\n",
    "        dataset=\"Alpha158\",\n",
    "        universe=\"\",\n",
    "        exclude=False,\n",
    "        exp_folder_name: str = \"mlruns\",\n",
    "        wait_when_err: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        models=\"lightgbm\", dataset=\"Alpha158\", universe=\"csi500\" will result in running the following config:\n",
    "        benchmarks/LightGBM/workflow_config_lightgbm_Alpha158_csi500.yaml\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        times : int\n",
    "            determines how many times the model should be running.\n",
    "        models : str or list\n",
    "            determines the specific model or list of models to run or exclude.\n",
    "        exclude : boolean\n",
    "            determines whether the model being used is excluded or included.\n",
    "        dataset : str\n",
    "            determines the dataset to be used for each model.\n",
    "        universe : str\n",
    "            the stock universe of the dataset.\n",
    "            default \"\" indicates that\n",
    "        exp_folder_name: str\n",
    "            the name of the experiment folder\n",
    "        wait_when_err : bool\n",
    "            wait when errors raised when executing commands\n",
    "\n",
    "            # Case 7 - run lightgbm model on csi500.\n",
    "            python run_all_model.py run 3 lightgbm Alpha158 csi500\n",
    "\n",
    "        \"\"\"\n",
    "        self._init_qlib(exp_folder_name)\n",
    "\n",
    "        # get all folders\n",
    "        folders = get_all_folders(models, exclude)\n",
    "        # init error messages:\n",
    "        errors = dict()\n",
    "        # run all the model for iterations\n",
    "        for fn in folders:\n",
    "            print(fn, folders)\n",
    "            # get all files\n",
    "            sys.stderr.write(\"Retrieving files...\\n\")\n",
    "            yaml_path, req_path = get_all_files(folders[fn], dataset, universe=universe)\n",
    "            if yaml_path is None:\n",
    "                sys.stderr.write(f\"There is no {dataset}.yaml file in {folders[fn]}\")\n",
    "                continue\n",
    "            sys.stderr.write(\"\\n\")\n",
    "            \n",
    "            from qlib.workflow.cli import render_template, workflow\n",
    "            # Render the template\n",
    "            rendered_yaml = render_template(yaml_path)\n",
    "            config = yaml.safe_load(rendered_yaml)\n",
    "            recorder = task_train(config.get(\"task\"), experiment_name=fn)\n",
    "            recorder.save_objects(config=config)\n",
    "            \n",
    "            # run workflow_by_config for multiple times\n",
    "            for i in range(times):\n",
    "                sys.stderr.write(f\"Running the model: {fn} for iteration {i+1}...\\n\")\n",
    "                                \n",
    "                errs = execute(\n",
    "                    f\"qrun {yaml_path} {fn} {exp_folder_name}\",\n",
    "                    # f\"python -m pdb {debug_qrun} {yaml_path} {fn} {exp_folder_name}\",\n",
    "                    wait_when_err=wait_when_err,\n",
    "                )\n",
    "                if errs is not None:\n",
    "                    _errs = errors.get(fn, {})\n",
    "                    _errs.update({i: errs})\n",
    "                    errors[fn] = _errs\n",
    "                sys.stderr.write(\"\\n\")\n",
    "        # print errors\n",
    "        sys.stderr.write(f\"Here are some of the errors of the models...\\n\")\n",
    "        pprint(errors)\n",
    "        self._collect_results(exp_folder_name, dataset)\n",
    "\n",
    "    def _collect_results(self, exp_folder_name, dataset):\n",
    "        folders = get_all_folders(exp_folder_name, dataset)\n",
    "        # getting all results\n",
    "        sys.stderr.write(f\"Retrieving results...\\n\")\n",
    "        results = get_all_results(folders)\n",
    "        if len(results) > 0:\n",
    "            # calculating the mean and std\n",
    "            sys.stderr.write(f\"Calculating the mean and std of results...\\n\")\n",
    "            results = cal_mean_std(results)\n",
    "            # generating md table\n",
    "            sys.stderr.write(f\"Generating markdown table...\\n\")\n",
    "            gen_and_save_md_table(results, dataset)\n",
    "            sys.stderr.write(\"\\n\")\n",
    "        sys.stderr.write(\"\\n\")\n",
    "        # move results folder\n",
    "        folder_with_stamp = exp_folder_name + f\"_{dataset}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "        shutil.move(exp_folder_name, folder_with_stamp)\n",
    "        shutil.move(\"table.md\", f\"{folder_with_stamp}/table.md\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # fire.Fire(ModelRunner)  # run all the model\n",
    "    runner = ModelRunner()\n",
    "    runner.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
