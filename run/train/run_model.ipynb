{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 15:12:05.706 | WARNING  | qlib.tests.data:qlib_data:195 - Data already exists: ./.qlib/qlib_data/cn_data, the data download will be skipped\n",
      "\tIf downloading is required: `exists_skip=False` or `change target_dir`\n",
      "[28124:MainThread](2024-08-20 15:12:05,708) INFO - qlib.Initialization - [config.py:416] - default_conf: client.\n",
      "[28124:MainThread](2024-08-20 15:12:05,713) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[28124:MainThread](2024-08-20 15:12:05,714) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': WindowsPath('C:/Users/chuyin.wang/Desktop/share/fin/trader/run/train/.qlib/qlib_data/cn_data')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost {'XGBoost': 'C:\\\\Users\\\\chuyin.wang\\\\Desktop\\\\share\\\\fin\\\\trader\\\\run\\\\train\\\\benchmarks\\\\XGBoost'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving files...\n",
      "\n",
      "[28124:MainThread](2024-08-20 15:12:05,724) INFO - qlib.qrun - [cli.py:78] - Render the template with the context: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ========================================================\n",
      "<qlib.contrib.model.xgboost.XGBModel object at 0x00000294F2A3BB50>\n",
      "Dataset: ========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28124:MainThread](2024-08-20 15:13:20,572) INFO - qlib.timer - [log.py:127] - Time cost: 71.535s | Loading data Done\n",
      "[28124:MainThread](2024-08-20 15:13:20,830) INFO - qlib.timer - [log.py:127] - Time cost: 0.087s | DropnaLabel Done\n",
      "[28124:MainThread](2024-08-20 15:13:21,463) INFO - qlib.timer - [log.py:127] - Time cost: 0.632s | CSZScoreNorm Done\n",
      "[28124:MainThread](2024-08-20 15:13:21,476) INFO - qlib.timer - [log.py:127] - Time cost: 0.901s | fit & process data Done\n",
      "[28124:MainThread](2024-08-20 15:13:21,477) INFO - qlib.timer - [log.py:127] - Time cost: 72.440s | Init data Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetH(handler=<qlib.contrib.data.handler.Alpha158 object at 0x00000294F2AFF710>, segments={'train': [datetime.date(2018, 1, 1), datetime.date(2018, 12, 31)], 'valid': [datetime.date(2019, 1, 1), datetime.date(2019, 12, 31)], 'test': [datetime.date(2020, 1, 1), datetime.date(2020, 8, 1)]})\n",
      "Dataset_Handler: ========================================================\n",
      "features/labels:                             KMID      KLEN     KMID2       KUP      KUP2  \\\n",
      "datetime   instrument                                                     \n",
      "2018-01-02 SH600000    0.008723  0.013481  0.647058  0.003965  0.294117   \n",
      "           SH600008    0.009709  0.017476  0.555558  0.003883  0.222221   \n",
      "           SH600009   -0.013333  0.026667 -0.499996  0.007333  0.275002   \n",
      "           SH600010    0.016260  0.024390  0.666668  0.004065  0.166664   \n",
      "           SH600011    0.014563  0.022654  0.642859  0.004854  0.214286   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "2020-07-31 SZ300413    0.011740  0.040868  0.287274  0.018873  0.461817   \n",
      "           SZ300433    0.030103  0.048605  0.619354  0.014111  0.290323   \n",
      "           SZ300498   -0.003356  0.023490 -0.142858  0.012164  0.517855   \n",
      "           SZ300601    0.008080  0.067009  0.120586  0.013750  0.205196   \n",
      "           SZ300628   -0.013750  0.040312 -0.341086  0.017187  0.426356   \n",
      "\n",
      "                           KLOW     KLOW2      KSFT     KSFT2     OPEN0  ...  \\\n",
      "datetime   instrument                                                    ...   \n",
      "2018-01-02 SH600000    0.000793  0.058825  0.005551  0.411767  0.991352  ...   \n",
      "           SH600008    0.003883  0.222221  0.009709  0.555558  0.990385  ...   \n",
      "           SH600009    0.006000  0.225001 -0.014667 -0.549997  1.013513  ...   \n",
      "           SH600010    0.004065  0.166668  0.016260  0.666673  0.984000  ...   \n",
      "           SH600011    0.003236  0.142854  0.012945  0.571427  0.985646  ...   \n",
      "...                         ...       ...       ...       ...       ...  ...   \n",
      "2020-07-31 SZ300413    0.010254  0.250909  0.003121  0.076366  0.988396  ...   \n",
      "           SZ300433    0.004390  0.090323  0.020383  0.419354  0.970776  ...   \n",
      "           SZ300498    0.007970  0.339288 -0.007550 -0.321424  1.003367  ...   \n",
      "           SZ300601    0.045179  0.674218  0.039509  0.589608  0.991984  ...   \n",
      "           SZ300628    0.009375  0.232558 -0.021563 -0.534884  1.013942  ...   \n",
      "\n",
      "                        VSUMN10   VSUMN20   VSUMN30   VSUMN60    VSUMD5  \\\n",
      "datetime   instrument                                                     \n",
      "2018-01-02 SH600000    0.388162  0.508938  0.531579  0.509718  0.226988   \n",
      "           SH600008    0.431781  0.484230  0.486603  0.507665  0.026740   \n",
      "           SH600009    0.428592  0.468054  0.550977  0.510013  0.368401   \n",
      "           SH600010    0.456156  0.531977  0.488366  0.494931 -0.113736   \n",
      "           SH600011    0.510931  0.554335  0.498614  0.490070 -0.428129   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "2020-07-31 SZ300413    0.559005  0.514765  0.531086  0.492531 -0.424739   \n",
      "           SZ300433    0.508023  0.507246  0.467712  0.490444  0.000004   \n",
      "           SZ300498    0.565064  0.523422  0.489674  0.488180 -0.545229   \n",
      "           SZ300601    0.265612  0.387342  0.425360  0.465201  0.537872   \n",
      "           SZ300628    0.510992  0.482686  0.511605  0.492685 -0.074103   \n",
      "\n",
      "                        VSUMD10   VSUMD20   VSUMD30   VSUMD60    LABEL0  \n",
      "datetime   instrument                                                    \n",
      "2018-01-02 SH600000    0.223677 -0.017876 -0.063158 -0.019435  0.000000  \n",
      "           SH600008    0.136438  0.031541  0.026794 -0.015329       NaN  \n",
      "           SH600009    0.142816  0.063893 -0.101953 -0.020027  0.001135  \n",
      "           SH600010    0.087688 -0.063954  0.023269  0.010138 -0.003984  \n",
      "           SH600011   -0.021863 -0.108670  0.002772  0.019860 -0.004747  \n",
      "...                         ...       ...       ...       ...       ...  \n",
      "2020-07-31 SZ300413   -0.118010 -0.029530 -0.062173  0.014938 -0.037566  \n",
      "           SZ300433   -0.016046 -0.014492  0.064577  0.019113 -0.031677  \n",
      "           SZ300498   -0.130127 -0.046844  0.020651  0.023640 -0.006531  \n",
      "           SZ300601    0.468775  0.225316  0.149280  0.069599  0.090264  \n",
      "           SZ300628   -0.021985  0.034628 -0.023210  0.014630  0.004142  \n",
      "\n",
      "[188100 rows x 159 columns]\n",
      "train_processor:  [<qlib.data.dataset.processor.DropnaLabel object at 0x00000294F2B1D2D0>, <qlib.data.dataset.processor.CSZScoreNorm object at 0x00000294F2B1D350>]\n",
      "infer_processor:  []\n",
      "process_type:  append\n",
      "XGBoost file:C:\\Users\\chuyin.wang\\Desktop\\share\\fin\\trader\\run\\train\\mlruns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28124:MainThread](2024-08-20 15:13:21,685) WARNING - qlib.workflow - [expm.py:230] - No valid experiment found. Create a new experiment with name XGBoost.\n",
      "[28124:MainThread](2024-08-20 15:13:21,715) INFO - qlib.workflow - [exp.py:258] - Experiment 315313931788076689 starts running ...\n",
      "[28124:MainThread](2024-08-20 15:13:21,719) INFO - qlib.workflow - [exp.py:193] - No valid recorder found. Create a new recorder with name r_XGBoost.\n",
      "[28124:MainThread](2024-08-20 15:13:22,004) INFO - qlib.workflow - [recorder.py:341] - Recorder d1dd8e90ab8b467cab9f06fdb443263d starts running under Experiment 315313931788076689 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model/Dataset Saving: ========================================================\n",
      "Model Fitting: ========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuyin.wang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [15:13:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.99683\tvalid-rmse:0.99833\n",
      "[20]\ttrain-rmse:0.97506\tvalid-rmse:0.99909\n",
      "[40]\ttrain-rmse:0.95794\tvalid-rmse:1.00019\n",
      "[52]\ttrain-rmse:0.94624\tvalid-rmse:1.00087\n",
      "Model Importance: ========================================================\n",
      "f0      407.0\n",
      "f1      334.0\n",
      "f3      170.0\n",
      "f5      149.0\n",
      "f38     117.0\n",
      "        ...  \n",
      "f124      2.0\n",
      "f63       2.0\n",
      "f123      2.0\n",
      "f153      1.0\n",
      "f155      1.0\n",
      "Length: 152, dtype: float64\n",
      "Recorder: ========================================================\n",
      "RecorderWrapper(provider=QlibRecorder(manager=MLflowExpManager(uri=file:C:\\Users\\chuyin.wang\\Desktop\\share\\fin\\trader\\run\\train\\mlruns)))\n",
      "MLflowRecorder(info={'class': 'Recorder', 'id': 'd1dd8e90ab8b467cab9f06fdb443263d', 'name': 'r_XGBoost', 'experiment_id': '315313931788076689', 'start_time': '2024-08-20 15:13:22', 'end_time': None, 'status': 'RUNNING'},\n",
      "               uri=file:C:\\Users\\chuyin.wang\\Desktop\\share\\fin\\trader\\run\\train\\mlruns,\n",
      "               artifact_uri=file:C:\\Users\\chuyin.wang\\Desktop\\share\\fin\\trader\\run\\train\\mlruns/315313931788076689/d1dd8e90ab8b467cab9f06fdb443263d/artifacts,\n",
      "               client=<mlflow.tracking.client.MlflowClient object at 0x00000294EBF895D0>)\n",
      "'C:\\\\Users\\\\chuyin.wang\\\\Desktop\\\\share\\\\fin\\\\trader\\\\run\\\\train\\\\mlruns\\\\315313931788076689\\\\d1dd8e90ab8b467cab9f06fdb443263d'\n",
      "Prediction: ========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28124:MainThread](2024-08-20 15:13:29,389) INFO - qlib.workflow - [record_temp.py:198] - Signal record 'pred.pkl' has been saved as the artifact of the Experiment 315313931788076689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The following are prediction results of the XGBModel model.'\n",
      "                          score\n",
      "datetime   instrument          \n",
      "2020-01-02 SH600000    0.023867\n",
      "           SH600004    0.000646\n",
      "           SH600009    0.012422\n",
      "           SH600010   -0.006539\n",
      "           SH600011   -0.008642\n",
      "                          score\n",
      "datetime   instrument          \n",
      "2020-01-02 SH600000    0.023867\n",
      "           SH600004    0.000646\n",
      "           SH600009    0.012422\n",
      "           SH600010   -0.006539\n",
      "           SH600011   -0.008642\n",
      "...                         ...\n",
      "2020-07-31 SZ300413   -0.220940\n",
      "           SZ300433   -0.366392\n",
      "           SZ300498   -0.024615\n",
      "           SZ300601   -0.018913\n",
      "           SZ300628   -0.047894\n",
      "\n",
      "[42000 rows x 1 columns]\n",
      "Signal Analysis: ========================================================\n",
      "{'IC': 0.017810058533359503,\n",
      " 'ICIR': 0.13533383654943704,\n",
      " 'Long-Avg Ann Return': 0.2953018331900239,\n",
      " 'Long-Avg Ann Sharpe': 1.0846698348712849,\n",
      " 'Long-Short Ann Return': 0.11152748297899961,\n",
      " 'Long-Short Ann Sharpe': 1.8121201767106265,\n",
      " 'Rank IC': 0.025232856087287276,\n",
      " 'Rank ICIR': 0.21182822323558348}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28124:MainThread](2024-08-20 15:13:30,182) INFO - qlib.timer - [log.py:127] - Time cost: 0.000s | waiting `async_log` Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest: ========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28124:MainThread](2024-08-20 15:13:30,333) INFO - qlib.backtest caller - [__init__.py:93] - Create new exchange\n",
      "[28124:MainThread](2024-08-20 15:13:56,724) WARNING - qlib.online operator - [exchange.py:219] - $close field data contains nan.\n",
      "[28124:MainThread](2024-08-20 15:13:56,727) WARNING - qlib.online operator - [exchange.py:219] - $close field data contains nan.\n",
      "[28124:MainThread](2024-08-20 15:13:56,732) WARNING - qlib.online operator - [exchange.py:226] - factor.day.bin file not exists or factor contains `nan`. Order using adjusted_price.\n",
      "[28124:MainThread](2024-08-20 15:13:56,733) WARNING - qlib.online operator - [exchange.py:228] - trade unit 100 is not supported in adjusted_price mode.\n",
      "[28124:MainThread](2024-08-20 15:14:02,726) WARNING - qlib.data - [data.py:665] - load calendar error: freq=day, future=True; return current calendar!\n",
      "[28124:MainThread](2024-08-20 15:14:02,728) WARNING - qlib.data - [data.py:668] - You can get future calendar by referring to the following document: https://github.com/microsoft/qlib/blob/main/scripts/data_collector/contrib/README.md\n",
      "[28124:MainThread](2024-08-20 15:14:02,749) WARNING - qlib.BaseExecutor - [executor.py:121] - `common_infra` is not set for <qlib.backtest.executor.SimulatorExecutor object at 0x00000294FBFC4310>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437a36694e5d44288435d358641cefdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "backtest loop:   0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuyin.wang\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qlib\\utils\\index_data.py:492: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(self.data)\n",
      "[28124:MainThread](2024-08-20 15:14:05,311) INFO - qlib.workflow - [record_temp.py:515] - Portfolio analysis record 'port_analysis_1day.pkl' has been saved as the artifact of the Experiment 315313931788076689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The following are analysis results of benchmark return(1day).'\n",
      "                       risk\n",
      "mean               0.001114\n",
      "std                0.016669\n",
      "annualized_return  0.265098\n",
      "information_ratio  1.030870\n",
      "max_drawdown      -0.171983\n",
      "'The following are analysis results of the excess return without cost(1day).'\n",
      "                       risk\n",
      "mean               0.000203\n",
      "std                0.006099\n",
      "annualized_return  0.048316\n",
      "information_ratio  0.513509\n",
      "max_drawdown      -0.039758\n",
      "'The following are analysis results of the excess return with cost(1day).'\n",
      "                       risk\n",
      "mean               0.000006\n",
      "std                0.006095\n",
      "annualized_return  0.001323\n",
      "information_ratio  0.014066\n",
      "max_drawdown      -0.045454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[28124:MainThread](2024-08-20 15:14:05,337) INFO - qlib.workflow - [record_temp.py:540] - Indicator analysis record 'indicator_analysis_1day.pkl' has been saved as the artifact of the Experiment 315313931788076689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The following are analysis results of indicators(1day).'\n",
      "     value\n",
      "ffr    1.0\n",
      "pa     0.0\n",
      "pos    0.0\n",
      "                                                  risk\n",
      "excess_return_without_cost mean               0.000203\n",
      "                           std                0.006099\n",
      "                           annualized_return  0.048316\n",
      "                           information_ratio  0.513509\n",
      "                           max_drawdown      -0.039758\n",
      "excess_return_with_cost    mean               0.000006\n",
      "                           std                0.006095\n",
      "                           annualized_return  0.001323\n",
      "                           information_ratio  0.014066\n",
      "                           max_drawdown      -0.045454\n",
      "Collect Result: ========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving results...\n",
      "Calculating the mean and std of results...\n",
      "Generating markdown table...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('| Model Name | Dataset | IC | ICIR | Rank IC | Rank ICIR | Annualized Return '\n",
      " '| Information Ratio | Max Drawdown |\\n'\n",
      " '|---|---|---|---|---|---|---|---|---|\\n'\n",
      " '| XGBoost | Alpha158 | 0.0178±0.00 | 0.1353±0.00| 0.0252±0.00 | 0.2118±0.00 '\n",
      " '| 0.0013±0.00 | 0.0141±0.00| -0.0455±0.00 |\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pip3 install ipykernel --upgrade\n",
    "# python3.11.exe -m ipykernel install --user\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import fire\n",
    "import time\n",
    "import glob\n",
    "import yaml\n",
    "import shutil\n",
    "import signal\n",
    "import logging\n",
    "import inspect\n",
    "import functools\n",
    "import statistics\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from operator import xor\n",
    "from pprint import pprint\n",
    "\n",
    "import qlib\n",
    "from qlib.config import C\n",
    "from qlib.data import D\n",
    "from qlib.workflow import R\n",
    "from qlib.workflow.cli import render_template\n",
    "from qlib.utils import set_log_with_config, init_instance_by_config, flatten_dict\n",
    "from qlib.utils.data import update_config\n",
    "from qlib.model.trainer import task_train\n",
    "from qlib.workflow.record_temp import SignalRecord, PortAnaRecord, SigAnaRecord\n",
    "from qlib.log import get_module_logger\n",
    "from qlib.tests.data import GetData\n",
    "\n",
    "set_log_with_config(C.logging_config)\n",
    "logger = get_module_logger(\"qrun\", logging.INFO)\n",
    "\n",
    "# decorator to check the arguments\n",
    "def only_allow_defined_args(function_to_decorate):\n",
    "    @functools.wraps(function_to_decorate)\n",
    "    def _return_wrapped(*args, **kwargs):\n",
    "        \"\"\"Internal wrapper function.\"\"\"\n",
    "        argspec = inspect.getfullargspec(function_to_decorate)\n",
    "        valid_names = set(argspec.args + argspec.kwonlyargs)\n",
    "        if \"self\" in valid_names:\n",
    "            valid_names.remove(\"self\")\n",
    "        for arg_name in kwargs:\n",
    "            if arg_name not in valid_names:\n",
    "                raise ValueError(\"Unknown argument seen '%s', expected: [%s]\" % (arg_name, \", \".join(valid_names)))\n",
    "        return function_to_decorate(*args, **kwargs)\n",
    "    return _return_wrapped\n",
    "\n",
    "# function to handle ctrl z and ctrl c\n",
    "def handler(signum, frame):\n",
    "    os.system(\"kill -9 %d\" % os.getpid())\n",
    "\n",
    "signal.signal(signal.SIGINT, handler)\n",
    "\n",
    "def print_class_attributes_and_methods(obj):\n",
    "    print(f\"Class: {obj.__class__.__name__}\")\n",
    "    print(\"Attributes and Methods:\")\n",
    "    for attribute in dir(obj):\n",
    "        # Filter out built-in attributes and methods (those starting with '__')\n",
    "        if not attribute.startswith(\"__\"):\n",
    "            try:\n",
    "                # Attempt to get the value of the attribute/method\n",
    "                attr_value = getattr(obj, attribute)\n",
    "                if callable(attr_value):\n",
    "                    print(f\"{attribute} (method) -> {attr_value}\")\n",
    "                else:\n",
    "                    print(f\"{attribute} (attribute) -> {attr_value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not access {attribute}: {e}\")\n",
    "\n",
    "# function to calculate the mean and std of a list in the results dictionary\n",
    "def cal_mean_std(results) -> dict:\n",
    "    mean_std = dict()\n",
    "    for fn in results:\n",
    "        mean_std[fn] = dict()\n",
    "        for metric in results[fn]:\n",
    "            mean = statistics.mean(results[fn][metric]) if len(results[fn][metric]) > 1 else results[fn][metric][0]\n",
    "            std = statistics.stdev(results[fn][metric]) if len(results[fn][metric]) > 1 else 0\n",
    "            mean_std[fn][metric] = [mean, std]\n",
    "    return mean_std\n",
    "\n",
    "# function to get all the folders benchmark folder\n",
    "def get_all_folders(models, exclude) -> dict:\n",
    "    folders = dict()\n",
    "    if isinstance(models, str):\n",
    "        model_list = models.split(\",\")\n",
    "        models = [m.lower().strip(\"[ ]\") for m in model_list]\n",
    "    elif isinstance(models, list):\n",
    "        models = [m.lower() for m in models]\n",
    "    elif models is None:\n",
    "        models = [f.name.lower() for f in os.scandir(\"benchmarks\")]\n",
    "    else:\n",
    "        raise ValueError(\"Input models type is not supported. Please provide str or list without space.\")\n",
    "    for f in os.scandir(\"benchmarks\"):\n",
    "        add = xor(bool(f.name.lower() in models), bool(exclude))\n",
    "        if add:\n",
    "            path = Path(\"benchmarks\") / f.name\n",
    "            folders[f.name] = str(path.resolve())\n",
    "    return folders\n",
    "\n",
    "# function to get all the files under the model folder\n",
    "def get_all_files(folder_path, dataset, universe=\"\") -> (str, str): # type: ignore\n",
    "    if universe != \"\":\n",
    "        universe = f\"_{universe}\"\n",
    "    yaml_path = str(Path(f\"{folder_path}\") / f\"*{dataset}{universe}.yaml\")\n",
    "    req_path = str(Path(f\"{folder_path}\") / f\"*.txt\")\n",
    "    yaml_file = glob.glob(yaml_path)\n",
    "    req_file = glob.glob(req_path)\n",
    "    if len(yaml_file) == 0:\n",
    "        return None, None\n",
    "    else:\n",
    "        return yaml_file[0], req_file[0]\n",
    "\n",
    "# function to retrieve all the results\n",
    "def get_all_results(config, dataset, folders, plot=False) -> dict:\n",
    "    results = dict()\n",
    "    for fn in folders:\n",
    "        try:\n",
    "            exp = R.get_exp(experiment_name=fn, create=False)\n",
    "        except ValueError:\n",
    "            # No experiment results\n",
    "            continue\n",
    "        recorders = exp.list_recorders()\n",
    "        result = dict()\n",
    "        result[\"annualized_return_with_cost\"] = list()\n",
    "        result[\"information_ratio_with_cost\"] = list()\n",
    "        result[\"max_drawdown_with_cost\"] = list()\n",
    "        result[\"ic\"] = list()\n",
    "        result[\"icir\"] = list()\n",
    "        result[\"rank_ic\"] = list()\n",
    "        result[\"rank_icir\"] = list()\n",
    "        for recorder_id in recorders:\n",
    "            if recorders[recorder_id].status == \"FINISHED\": # type: ignore\n",
    "                recorder = R.get_recorder(recorder_id=recorder_id, experiment_name=fn)\n",
    "                metrics = recorder.list_metrics()\n",
    "                if \"1day.excess_return_with_cost.annualized_return\" not in metrics:\n",
    "                    print(f\"{recorder_id} is skipped due to incomplete result\")\n",
    "                    continue\n",
    "                result[\"annualized_return_with_cost\"].append(metrics[\"1day.excess_return_with_cost.annualized_return\"])\n",
    "                result[\"information_ratio_with_cost\"].append(metrics[\"1day.excess_return_with_cost.information_ratio\"])\n",
    "                result[\"max_drawdown_with_cost\"].append(metrics[\"1day.excess_return_with_cost.max_drawdown\"])\n",
    "                result[\"ic\"].append(metrics[\"IC\"])\n",
    "                result[\"icir\"].append(metrics[\"ICIR\"])\n",
    "                result[\"rank_ic\"].append(metrics[\"Rank IC\"])\n",
    "                result[\"rank_icir\"].append(metrics[\"Rank ICIR\"])\n",
    "                \n",
    "                if plot:\n",
    "                    from qlib.contrib.report import analysis_model, analysis_position\n",
    "                    print(\"graphical analysis: ========================================================\")\n",
    "                    report_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\n",
    "                    analysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")\n",
    "                    analysis_position.report_graph(report_normal_df)\n",
    "                    analysis_position.risk_analysis_graph(analysis_df, report_normal_df)\n",
    "                    pred_df = recorder.load_object(\"pred.pkl\")\n",
    "                    label_df = dataset.prepare(\"test\", col_set=\"label\")\n",
    "                    label_df.columns = [\"label\"]\n",
    "                    pred_label = pd.concat([label_df, pred_df], axis=1, sort=True).reindex(label_df.index)\n",
    "                    analysis_position.score_ic_graph(pred_label)\n",
    "                    analysis_model.model_performance_graph(pred_label)\n",
    "                    # positions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\n",
    "                    # loaded_model = recorder.load_object(\"trained_model\")\n",
    "        results[fn] = result\n",
    "    return results\n",
    "\n",
    "# function to generate and save markdown table\n",
    "def gen_and_save_md_table(metrics, dataset_name):\n",
    "    table = \"| Model Name | Dataset | IC | ICIR | Rank IC | Rank ICIR | Annualized Return | Information Ratio | Max Drawdown |\\n\"\n",
    "    table += \"|---|---|---|---|---|---|---|---|---|\\n\"\n",
    "    for fn in metrics:\n",
    "        ic = metrics[fn][\"ic\"]\n",
    "        icir = metrics[fn][\"icir\"]\n",
    "        ric = metrics[fn][\"rank_ic\"]\n",
    "        ricir = metrics[fn][\"rank_icir\"]\n",
    "        ar = metrics[fn][\"annualized_return_with_cost\"]\n",
    "        ir = metrics[fn][\"information_ratio_with_cost\"]\n",
    "        md = metrics[fn][\"max_drawdown_with_cost\"]\n",
    "        table += f\"| {fn} | {dataset_name} | {ic[0]:5.4f}±{ic[1]:2.2f} | {icir[0]:5.4f}±{icir[1]:2.2f}| {ric[0]:5.4f}±{ric[1]:2.2f} | {ricir[0]:5.4f}±{ricir[1]:2.2f} | {ar[0]:5.4f}±{ar[1]:2.2f} | {ir[0]:5.4f}±{ir[1]:2.2f}| {md[0]:5.4f}±{md[1]:2.2f} |\\n\"\n",
    "    pprint(table)\n",
    "    with open(\"table.md\", \"w\") as f:\n",
    "        f.write(table)\n",
    "    return table\n",
    "\n",
    "def train(config, model, dataset, id: str = \"0\", uri_path: str = \"\", experiment_name: str = \"workflow\"):\n",
    "    \"\"\"train model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pred_score: pandas.DataFrame\n",
    "            predict scores\n",
    "        performance: dict\n",
    "            model performance\n",
    "    \"\"\"\n",
    "    ana_long_short = True\n",
    "    \n",
    "    # start exp\n",
    "    print(experiment_name,  uri_path)\n",
    "    with R.start(experiment_id=id, experiment_name=experiment_name, \n",
    "                 recorder_id=\"0\", recorder_name=f\"r_{experiment_name}\", \n",
    "                 uri=uri_path): # resume=True):\n",
    "        # record parameters\n",
    "        R.log_params(**flatten_dict(config))\n",
    "        \n",
    "        print(\"Model/Dataset Saving: ========================================================\")\n",
    "        R.save_objects(**{\"model.pkl\": model})\n",
    "        R.save_objects(**{\"dataset_class.pkl\": dataset})\n",
    "        dataset.config(dump_all=True, recursive=True) # include _data (with '_' at start)\n",
    "        R.save_objects(**{\"dataset_class_with_data.pkl\": dataset})\n",
    "        ##=============dump=============\n",
    "        # dataset.to_pickle(path=f\"{exp_folder_name}/dataset.pkl\") # dataset is an instance of qlib.data.dataset.DatasetH\n",
    "        ##=============reload=============\n",
    "        # with open(\"dataset.pkl\", \"rb\") as file_dataset:\n",
    "        #   import pickle\n",
    "        #     dataset = pickle.load(file_dataset)\n",
    "        \n",
    "        print(\"Model Fitting: ========================================================\")\n",
    "        model.fit(dataset)\n",
    "        \n",
    "        print(\"Model Importance: ========================================================\")\n",
    "        print(model.get_feature_importance())\n",
    "        \n",
    "        # prediction\n",
    "        print(\"Recorder: ========================================================\")\n",
    "        recorder = R.get_recorder()\n",
    "        pprint(R)\n",
    "        pprint(recorder)\n",
    "        pprint(recorder.get_local_dir()) # type: ignore\n",
    "        rid = recorder.id\n",
    "        print(\"Prediction: ========================================================\")\n",
    "        sr = SignalRecord(model, dataset, recorder)\n",
    "        sr.generate()\n",
    "        from qlib.contrib.model.xgboost import XGBModel\n",
    "        # XGBModel.predict(DatasetH)\n",
    "        pred_score = sr.load(\"pred.pkl\")\n",
    "        pprint(pred_score)\n",
    "\n",
    "        # calculate ic and ric\n",
    "        print(\"Signal Analysis: ========================================================\")\n",
    "        sar = SigAnaRecord(recorder,\n",
    "                           ana_long_short=ana_long_short, # generate long/short data\n",
    "                           ann_scaler=252, # convert daily to annual\n",
    "                           )\n",
    "        sar.generate()\n",
    "        ic = sar.load(\"ic.pkl\")\n",
    "        ric = sar.load(\"ric.pkl\")\n",
    "        if ana_long_short:\n",
    "            long_avg_r = sar.load(\"long_avg_r.pkl\")\n",
    "            long_short_r = sar.load(\"long_short_r.pkl\")\n",
    "            sig_ana = {\"ic\": ic, \"ric\": ric, \"long_avg_r\": long_avg_r, \"long_short_r\": long_short_r}\n",
    "        else:\n",
    "            sig_ana = {\"ic\": ic, \"ric\": ric}\n",
    "        # uri_path = R.get_uri()\n",
    "    return pred_score, sig_ana, rid\n",
    "\n",
    "def backtest_analysis(pred, rid, config, uri_path: str = \"\", experiment_name: str = \"workflow\"):\n",
    "    \"\"\"backtest and analysis\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rid : str\n",
    "        the id of the recorder to be used in this function\n",
    "    uri_path: str\n",
    "        mlflow uri path\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    analysis : pandas.DataFrame\n",
    "        the analysis result\n",
    "    \"\"\"\n",
    "    \n",
    "    with R.uri_context(uri=uri_path):\n",
    "        recorder = R.get_recorder(experiment_name=experiment_name, recorder_id=rid)\n",
    "        \n",
    "    port_analysis_config = config.get(\"port_analysis_config\")\n",
    "    print(\"Backtest: ========================================================\")\n",
    "    # backtest\n",
    "    par = PortAnaRecord(recorder, port_analysis_config, risk_analysis_freq=\"day\")\n",
    "    par.generate()\n",
    "    analysis_df = par.load(\"port_analysis_1day.pkl\")\n",
    "    print(analysis_df)\n",
    "    return analysis_df\n",
    "\n",
    "def collect_results(config, dataset, exp_folder_name, dataset_name, plot):\n",
    "    folders = get_all_folders(exp_folder_name, dataset_name)\n",
    "    # getting all results\n",
    "    sys.stderr.write(f\"Retrieving results...\\n\")\n",
    "    results = get_all_results(config, dataset, folders, plot)\n",
    "    if len(results) > 0:\n",
    "        # calculating the mean and std\n",
    "        sys.stderr.write(f\"Calculating the mean and std of results...\\n\")\n",
    "        results = cal_mean_std(results)\n",
    "        # generating md table\n",
    "        sys.stderr.write(f\"Generating markdown table...\\n\")\n",
    "        gen_and_save_md_table(results, dataset_name)\n",
    "        sys.stderr.write(\"\\n\")\n",
    "    sys.stderr.write(\"\\n\")\n",
    "\n",
    "class ModelRunner:\n",
    "    # def __init__(self):\n",
    "    #     self.run()\n",
    "        \n",
    "    def _init_qlib(self, exp_folder_name, uri_path):\n",
    "        # init qlib\n",
    "        provider_uri = \"./.qlib/qlib_data/cn_data\"\n",
    "        # config[\"qlib_init\"][\"provider_uri\"]\n",
    "        # config[\"qlib_init\"][\"region\"]\n",
    "        GetData().qlib_data(\n",
    "          name=\"qlib_data\",\n",
    "          target_dir=provider_uri,\n",
    "          interval=\"1d\",\n",
    "          region=\"cn\",\n",
    "          exists_skip=True\n",
    "          )\n",
    "        \n",
    "        # p = Path(\"./.qlib/qlib_data/cn_data/financial\").expanduser()\n",
    "        # if not p.exists():\n",
    "        #     !cd ../../scripts/data_collector/pit/ && pip install -r requirements.txt\n",
    "        #     !cd ../../scripts/data_collector/pit/ && python collector.py download_data --source_dir ./.qlib/stock_data/source/pit --start 2000-01-01 --end 2020-01-01 --interval quarterly --symbol_regex \"^(600519|000725).*\"\n",
    "        #     !cd ../../scripts/data_collector/pit/ && python collector.py normalize_data --interval quarterly --source_dir ./.qlib/stock_data/source/pit --normalize_dir ./.qlib/stock_data/source/pit_normalized\n",
    "        #     !cd ../../scripts/ && python dump_pit.py dump --csv_path ./.qlib/stock_data/source/pit_normalized --qlib_dir ./.qlib/qlib_data/cn_data --interval quarterly\n",
    "        \n",
    "        qlib.init(\n",
    "            exp_manager={\n",
    "                \"class\": \"MLflowExpManager\",\n",
    "                \"module_path\": \"qlib.workflow.expm\",\n",
    "                \"kwargs\": {\n",
    "                    \"uri\": uri_path,\n",
    "                    \"default_exp_name\": \"Experiment\",\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # function to run the all the models\n",
    "    @only_allow_defined_args\n",
    "    def run(\n",
    "        self,\n",
    "        models_name=['xgboost'], # None,\n",
    "        dataset_name=\"Alpha158\",\n",
    "        universe=\"\",\n",
    "        exclude=False,\n",
    "        exp_folder_name: str = \"mlruns\",\n",
    "        plot: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        models=\"lightgbm\", dataset=\"Alpha158\", universe=\"csi500\" will result in running the following config:\n",
    "        benchmarks/LightGBM/workflow_config_lightgbm_Alpha158_csi500.yaml\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        models : str or list\n",
    "            determines the specific model or list of models to run or exclude.\n",
    "        exclude : boolean\n",
    "            determines whether the model being used is excluded or included.\n",
    "        dataset : str\n",
    "            determines the dataset to be used for each model.\n",
    "        universe : str\n",
    "            the stock universe of the dataset.\n",
    "            default \"\" indicates that\n",
    "        exp_folder_name: str\n",
    "            the name of the experiment folder\n",
    "\n",
    "            # Case 7 - run lightgbm model on csi500.\n",
    "            python run_all_model.py run 3 lightgbm Alpha158 csi500\n",
    "\n",
    "        \"\"\"\n",
    "        uri_path = \"file:\" + str(Path(os.getcwd()).joinpath(exp_folder_name).resolve())\n",
    "        self._init_qlib(exp_folder_name, uri_path)\n",
    "\n",
    "        # get all folders\n",
    "        folders = get_all_folders(models_name, exclude)\n",
    "        # run all the model for iterations\n",
    "        for idx, fn in enumerate(folders):\n",
    "            print(fn, folders)\n",
    "            # get all files\n",
    "            sys.stderr.write(\"Retrieving files...\\n\")\n",
    "            yaml_path, req_path = get_all_files(folders[fn], dataset_name, universe=universe)\n",
    "            if yaml_path is None:\n",
    "                sys.stderr.write(f\"There is no {dataset_name}.yaml file in {folders[fn]}\")\n",
    "                continue\n",
    "            sys.stderr.write(\"\\n\")\n",
    "            \n",
    "            # Render the template\n",
    "            rendered_yaml = render_template(yaml_path)\n",
    "            config = yaml.safe_load(rendered_yaml)\n",
    "            \n",
    "            # model initialization\n",
    "            print(\"Model: ========================================================\")\n",
    "            model = init_instance_by_config(config[\"task\"][\"model\"])\n",
    "            pprint(model)\n",
    "            print(\"Dataset: ========================================================\")\n",
    "            dataset = init_instance_by_config(config[\"task\"][\"dataset\"])\n",
    "            pprint(dataset)\n",
    "            \n",
    "            print(\"Dataset_Handler: ========================================================\")\n",
    "            hd = dataset.handler\n",
    "            print(\"features/labels: \", hd.fetch(col_set=\"__all\", data_key=\"infer\")) # raw/learn/infer\n",
    "            # print(\"feature/label formula: \", hd.data_loader.fields)\n",
    "            print(\"train_processor: \", hd.learn_processors)\n",
    "            print(\"infer_processor: \", hd.infer_processors)\n",
    "            print(\"process_type: \", hd.process_type) # independent/append (dictates how processors apply on datesets)\n",
    "            \n",
    "            pred, sig_ana, rid = train(config, model, dataset, str(idx+1), uri_path, experiment_name=fn)\n",
    "            # assert ic/ric >= 0\n",
    "            \n",
    "            analyze_df = backtest_analysis(pred, rid, config, uri_path, experiment_name=fn)\n",
    "            # assert \"excess_return_with_cost\"/\"annualized_return\" >= 0.05\n",
    "            # assert not analyze_df.isna().any().any()\n",
    "        \n",
    "        plot = False\n",
    "        analysis = True\n",
    "        rename = False\n",
    "        print(\"Collect Result: ========================================================\")\n",
    "        if analysis:\n",
    "          collect_results(config, dataset, exp_folder_name, dataset_name, plot)\n",
    "          shutil.move(\"table.md\", f\"{exp_folder_name}/table.md\")\n",
    "        \n",
    "        if rename:\n",
    "          # move results folder\n",
    "          folder_with_stamp = exp_folder_name + f\"_{dataset_name}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "          shutil.move(exp_folder_name, folder_with_stamp)\n",
    "          \n",
    "if __name__ == \"__main__\":\n",
    "    # fire.Fire(ModelRunner)  # run all the model\n",
    "    runner = ModelRunner()\n",
    "    runner.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
